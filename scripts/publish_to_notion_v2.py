#!/usr/bin/env python3
"""Enhanced FM-LS-PROFIT v1.2.1 publisher - extracts ALL 76 requirements"""
import json, urllib.request, ssl, time, re, docx, sys

ssl._create_default_https_context = ssl._create_unverified_context

# === CONFIG ===
TOKEN = "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"
with open("/Users/antonsahovskii/Documents/claude-agents/fm-review-system/docs/notion-config.json") as f:
    CFG = json.load(f)

FM_DB = CFG["fm_database"]
REQ_DB = CFG["requirements_database"]
GLO_DB = CFG["glossary_database"]
RISK_DB = CFG["risks_database"]
VER_DB = CFG["versions_database"]

HEADERS = {
    "Authorization": f"Bearer {TOKEN}",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28"
}

DOC_PATH = "/Users/antonsahovskii/Documents/claude-agents/fm-review-system/projects/PROJECT_SHPMNT_PROFIT/FM_DOCUMENTS/FM-LS-PROFIT-v1.2.1.docx"

def api(method, path, data=None):
    url = f"https://api.notion.com/v1/{path}"
    body = json.dumps(data).encode() if data else None
    req = urllib.request.Request(url, data=body, headers=HEADERS, method=method)
    try:
        with urllib.request.urlopen(req) as resp:
            return json.loads(resp.read())
    except urllib.error.HTTPError as e:
        err = json.loads(e.read())
        print(f"  API ERROR {e.code}: {err.get('message','?')[:200]}", file=sys.stderr)
        return None

def rich_text(text, max_len=2000):
    if not text:
        return []
    text = str(text)[:max_len]
    return [{"text": {"content": text}}]

def create_page_in_db(db_id, properties):
    return api("POST", "pages", {
        "parent": {"database_id": db_id},
        "properties": properties
    })

def query_db(db_id):
    pages = []
    cursor = None
    while True:
        payload = {"page_size": 100}
        if cursor:
            payload["start_cursor"] = cursor
        r = api("POST", f"databases/{db_id}/query", payload)
        if not r:
            break
        pages.extend(r.get("results", []))
        if not r.get("has_more"):
            break
        cursor = r.get("next_cursor")
        time.sleep(0.2)
    return pages

def archive_page(page_id):
    return api("PATCH", f"pages/{page_id}", {"archived": True})

# === LOAD DOCUMENT ===
print("=" * 60)
print("ENHANCED NOTION PUBLISHER v2")
print("=" * 60)
print("\n=== LOADING DOCUMENT ===")
doc = docx.Document(DOC_PATH)
title = "ÐšÐžÐÐ¢Ð ÐžÐ›Ð¬ Ð Ð•ÐÐ¢ÐÐ‘Ð•Ð›Ð¬ÐÐžÐ¡Ð¢Ð˜ ÐžÐ¢Ð“Ð Ð£Ð—ÐžÐš ÐŸÐž Ð›Ð¡"
print(f"  Title: {title}")
print(f"  Paragraphs: {len(doc.paragraphs)}")
print(f"  Tables: {len(doc.tables)}")

# === STEP 0: Clear existing data ===
print("\n=== STEP 0: Clear existing data ===")
total_cleared = 0
for name, db_id in [("FM", FM_DB), ("Requirements", REQ_DB), ("Glossary", GLO_DB), ("Risks", RISK_DB), ("Versions", VER_DB)]:
    pages = query_db(db_id)
    for p in pages:
        archive_page(p["id"])
        total_cleared += 1
        time.sleep(0.1)
    if pages:
        print(f"  Cleared {len(pages)} from {name}")
print(f"  Total cleared: {total_cleared}")

# === STEP 1: Create FM record ===
print("\n=== STEP 1: Create FM record ===")
fm_page = create_page_in_db(FM_DB, {
    "ÐšÐ¾Ð´": {"title": rich_text("FM-LS-PROFIT")},
    "ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ": {"rich_text": rich_text(title)},
    "Ð’ÐµÑ€ÑÐ¸Ñ": {"rich_text": rich_text("1.2.1")},
    "Ð¡Ñ‚Ð°Ñ‚ÑƒÑ": {"select": {"name": "Draft"}},
    "ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚": {"select": {"name": "P1"}},
    "ÐžÐ±Ð»Ð°ÑÑ‚ÑŒ": {"multi_select": [{"name": "ÐŸÑ€Ð¾Ð´Ð°Ð¶Ð¸"}, {"name": "Ð›Ð¾Ð³Ð¸ÑÑ‚Ð¸ÐºÐ°"}, {"name": "Ð¤Ð¸Ð½Ð°Ð½ÑÑ‹"}]},
    "Ð¡Ð¸ÑÑ‚ÐµÐ¼Ñ‹": {"multi_select": [{"name": "1Ð¡:Ð£Ð¢"}, {"name": "1Ð¡:ERP"}]}
})

if fm_page:
    fm_page_id = fm_page["id"]
    fm_page_url = fm_page["url"]
    print(f"  Created: {fm_page_id}")
    print(f"  URL: {fm_page_url}")
else:
    print("  FAILED to create FM page")
    sys.exit(1)

time.sleep(0.3)

# === STEP 2: Add content blocks ===
print("\n=== STEP 2: Add content blocks ===")

def add_blocks(page_id, blocks):
    for i in range(0, len(blocks), 100):
        chunk = blocks[i:i+100]
        r = api("PATCH", f"blocks/{page_id}/children", {"children": chunk})
        if r:
            print(f"  Added {len(chunk)} blocks (batch {i//100 + 1})")
        else:
            print(f"  FAILED batch {i//100 + 1}")
        time.sleep(0.5)

def make_heading(level, text):
    key = f"heading_{level}"
    return {"object": "block", "type": key, key: {"rich_text": rich_text(text)}}

def make_paragraph(text):
    if not text or not text.strip():
        return None
    return {"object": "block", "type": "paragraph", "paragraph": {"rich_text": rich_text(text)}}

def make_bullet(text):
    return {"object": "block", "type": "bulleted_list_item", "bulleted_list_item": {"rich_text": rich_text(text)}}

def make_callout(text, emoji="ðŸ’¡"):
    return {
        "object": "block",
        "type": "callout",
        "callout": {
            "rich_text": rich_text(text),
            "icon": {"type": "emoji", "emoji": emoji}
        }
    }

def make_divider():
    return {"object": "block", "type": "divider", "divider": {}}

blocks = []
blocks.append(make_heading(1, title))
blocks.append(make_paragraph("Ð’ÐµÑ€ÑÐ¸Ñ: 1.2.1 | Ð”Ð°Ñ‚Ð°: 29.01.2026 | Ð¡Ñ‚Ð°Ñ‚ÑƒÑ: Draft"))
blocks.append(make_divider())

for p in doc.paragraphs[2:]:
    text = p.text.strip()
    if not text:
        continue

    style = p.style.name if p.style else "Normal"

    # Special callouts for warnings
    if text.startswith("âš ï¸") or text.startswith("â›”"):
        emoji = "âš ï¸" if text.startswith("âš ï¸") else "ðŸš«"
        blocks.append(make_callout(text, emoji))
    elif style == "Heading 1":
        blocks.append(make_heading(1, text))
    elif style == "Heading 2":
        blocks.append(make_heading(2, text))
    elif style == "Heading 3":
        blocks.append(make_heading(3, text))
    elif style == "List Paragraph" or text.startswith("â€¢") or text.startswith("-"):
        blocks.append(make_bullet(text.lstrip("â€¢- ")))
    else:
        block = make_paragraph(text)
        if block:
            blocks.append(block)

blocks = [b for b in blocks if b]
print(f"  Parsed {len(blocks)} blocks")
add_blocks(fm_page_id, blocks)

# === STEP 3: Extract ALL requirements (76) ===
print("\n=== STEP 3: Extract ALL requirements ===")
req_pattern = re.compile(r'(LS-(?:BR|FR|WF|RPT|NFR|INT|SEC)-\d{3}[a-z]?)')

# Collect all text with requirement codes
all_texts = []
for p in doc.paragraphs:
    all_texts.append(p.text)
for table in doc.tables:
    for row in table.rows:
        for cell in row.cells:
            all_texts.append(cell.text)

full_text = "\n".join(all_texts)

# Find all unique codes
all_matches = req_pattern.findall(full_text)
found_codes = sorted(set(all_matches), key=lambda x: (x.split('-')[1], int(re.search(r'\d+', x).group())))
print(f"  Found {len(found_codes)} unique requirement codes")

# For each code, find its context
requirements = {}
for code in found_codes:
    # Find paragraph containing this code
    for text in all_texts:
        if code in text:
            # Get description - text after the code
            idx = text.find(code)
            desc = text[idx + len(code):].strip(" :.-â€“")
            if len(desc) > 10:
                requirements[code] = {
                    "code": code,
                    "type": code.split("-")[1],
                    "desc": desc[:500]
                }
                break

    if code not in requirements:
        requirements[code] = {
            "code": code,
            "type": code.split("-")[1],
            "desc": f"Ð¢Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ðµ {code}"
        }

# Type descriptions
type_names = {
    "BR": "Ð‘Ð¸Ð·Ð½ÐµÑ-Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð¾",
    "FR": "Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ðµ",
    "WF": "ÐŸÑ€Ð¾Ñ†ÐµÑÑ/Ð¡Ð¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð¸Ðµ",
    "RPT": "ÐžÑ‚Ñ‡ÐµÑ‚/ÐÐ½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ°",
    "NFR": "ÐÐµÑ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾Ðµ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ðµ",
    "INT": "Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ",
    "SEC": "Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ"
}

# Create requirements in Notion
req_ids = []
for code, req in sorted(requirements.items()):
    type_code = req["type"]
    name = f"{type_names.get(type_code, type_code)}: {req['desc'][:150]}"

    r = create_page_in_db(REQ_DB, {
        "ÐšÐ¾Ð´": {"title": rich_text(req["code"])},
        "ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ": {"rich_text": rich_text(name)},
        "Ð¢Ð¸Ð¿": {"select": {"name": type_code}},
        "Ð¡Ñ‚Ð°Ñ‚ÑƒÑ": {"select": {"name": "New"}},
        "ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚": {"select": {"name": "P1 (MVP)"}}
    })
    if r:
        req_ids.append(r["id"])
    time.sleep(0.12)

print(f"  Created {len(req_ids)} requirements")

# === STEP 4: Create Glossary ===
print("\n=== STEP 4: Create Glossary ===")
glossary_items = [
    ("LS-BR-XXX", "Ð‘Ð¸Ð·Ð½ÐµÑ-Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð° (Business Rules)", "Ð Ð°ÑÑ‡ÐµÑ‚Ñ‹, Ð»Ð¸Ð¼Ð¸Ñ‚Ñ‹, ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒ Ñ€ÐµÐ½Ñ‚Ð°Ð±ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸, Ð¿Ð¾Ñ€Ð¾Ð³Ð¾Ð²Ñ‹Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ", "BR"),
    ("LS-FR-XXX", "Ð¤ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ (Functional Requirements)", "Ð¤Ð¾Ñ€Ð¼Ñ‹, ÑÑ‚Ð°Ñ‚ÑƒÑÑ‹, Ð¿Ð¾Ð»Ñ, UI-ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñ‹, Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹Ñ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ", "FR"),
    ("LS-WF-XXX", "ÐŸÑ€Ð¾Ñ†ÐµÑÑÑ‹ Ð¸ ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð¸Ñ (Workflow)", "ÐœÐ°Ñ€ÑˆÑ€ÑƒÑ‚Ñ‹ ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð¸Ñ, SLA, ÑÑÐºÐ°Ð»Ð°Ñ†Ð¸Ð¸, ÑƒÐ²ÐµÐ´Ð¾Ð¼Ð»ÐµÐ½Ð¸Ñ", "WF"),
    ("LS-RPT-XXX", "ÐžÑ‚Ñ‡ÐµÑ‚Ñ‹ Ð¸ Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸ÐºÐ° (Reports)", "Ð”Ð°ÑˆÐ±Ð¾Ñ€Ð´Ñ‹, Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÐ¸, KPI, Ð°Ð½Ð°Ð»Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ðµ Ñ„Ð¾Ñ€Ð¼Ñ‹", "RPT"),
    ("LS-NFR-XXX", "ÐÐµÑ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ñ", "ÐŸÑ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ, Ð½Ð°Ð´ÐµÐ¶Ð½Ð¾ÑÑ‚ÑŒ, Ð¼Ð°ÑÑˆÑ‚Ð°Ð±Ð¸Ñ€ÑƒÐµÐ¼Ð¾ÑÑ‚ÑŒ", "NFR"),
    ("LS-INT-XXX", "Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¸", "Ð’Ð½ÐµÑˆÐ½Ð¸Ðµ ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹, API, Ð¾Ð±Ð¼ÐµÐ½ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸", "INT"),
    ("LS-SEC-XXX", "Ð‘ÐµÐ·Ð¾Ð¿Ð°ÑÐ½Ð¾ÑÑ‚ÑŒ", "ÐŸÑ€Ð°Ð²Ð° Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð°, Ð°ÑƒÐ´Ð¸Ñ‚, Ð·Ð°Ñ‰Ð¸Ñ‚Ð° Ð´Ð°Ð½Ð½Ñ‹Ñ…", "SEC"),
    ("ÐÐŸÐ¡Ð¡", "ÐÐ°ÐºÐ¾Ð¿Ð»ÐµÐ½Ð½Ð°Ñ ÐŸÐ¾Ð»Ð½Ð°Ñ Ð¡ÐµÐ±ÐµÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ", "ÐŸÐ¾Ð»Ð½Ð°Ñ ÑÐµÐ±ÐµÑÑ‚Ð¾Ð¸Ð¼Ð¾ÑÑ‚ÑŒ Ð·Ð°ÐºÑƒÐ¿ÐºÐ¸ Ñ‚Ð¾Ð²Ð°Ñ€Ð° Ñƒ Ð¿Ð¾ÑÑ‚Ð°Ð²Ñ‰Ð¸ÐºÐ° Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ Ð²ÑÐµÑ… Ð´Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ñ€Ð°ÑÑ…Ð¾Ð´Ð¾Ð²", ""),
    ("Ð›Ð¡", "Ð›Ð¾Ð³Ð¸ÑÑ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ Ð¡Ð¿ÐµÑ†Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ñ", "Ð”Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚-Ð·Ð°ÑÐ²ÐºÐ° ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð° Ð½Ð° Ð¿Ð¾ÑÑ‚Ð°Ð²ÐºÑƒ Ñ‚Ð¾Ð²Ð°Ñ€Ð¾Ð² Ñ ÑƒÐºÐ°Ð·Ð°Ð½Ð¸ÐµÐ¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð° Ð¸ ÑƒÑÐ»Ð¾Ð²Ð¸Ð¹", ""),
    ("Ð ÐµÐ½Ñ‚Ð°Ð±ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ", "ÐŸÐ¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»ÑŒ ÑÑ„Ñ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ð¸", "Ð ÐµÐ½Ñ‚Ð°Ð±ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ = (Ð¦ÐµÐ½Ð° - ÐÐŸÐ¡Ð¡) / Ð¦ÐµÐ½Ð° * 100%. Ð¦ÐµÐ»ÐµÐ²Ð¾Ðµ Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ >= 0%", ""),
    ("Ð Ð‘Ð®", "Ð ÑƒÐºÐ¾Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒ Ð‘Ð¸Ð·Ð½ÐµÑ-Ð®Ð½Ð¸Ñ‚Ð°", "ÐžÑ‚Ð²ÐµÑ‚ÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ð¹ Ð·Ð° ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð¸Ðµ ÑÐ´ÐµÐ»Ð¾Ðº Ñ Ð¾Ñ‚ÐºÐ»Ð¾Ð½ÐµÐ½Ð¸ÐµÐ¼ Ñ€ÐµÐ½Ñ‚Ð°Ð±ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ 1-15%", ""),
    ("Cherry-picking", "Ð’Ñ‹Ð±Ð¾Ñ€ Ð²Ñ‹Ð³Ð¾Ð´Ð½Ñ‹Ñ… Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¹", "Ð Ð¸ÑÐº: ÐºÐ»Ð¸ÐµÐ½Ñ‚ Ð²Ñ‹Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð¸Ð·ÐºÐ¾Ð¼Ð°Ñ€Ð¶Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸, Ð¾ÑÑ‚Ð°Ð²Ð»ÑÑ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð¼Ð°Ñ€Ð¶Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ", ""),
    ("Cream-skimming", "Ð¡Ð½ÑÑ‚Ð¸Ðµ ÑÐ»Ð¸Ð²Ð¾Ðº", "Ð Ð¸ÑÐº: ÐºÐ»Ð¸ÐµÐ½Ñ‚ ÑÐ½Ð°Ñ‡Ð°Ð»Ð° Ð·Ð°Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð¼Ð°Ñ€Ð¶Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸, Ð·Ð°Ñ‚ÐµÐ¼ Ð¾Ñ‚ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ÑÑ Ð¾Ñ‚ Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ°", ""),
    ("SLA", "Service Level Agreement", "Ð¡Ð¾Ð³Ð»Ð°ÑˆÐµÐ½Ð¸Ðµ Ð¾Ð± ÑƒÑ€Ð¾Ð²Ð½Ðµ ÑÐµÑ€Ð²Ð¸ÑÐ°. ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ ÑÑ€Ð¾ÐºÐ¸ Ñ€ÐµÐ°ÐºÑ†Ð¸Ð¸ Ð¸ ÑÑÐºÐ°Ð»Ð°Ñ†Ð¸Ð¸ Ð¿Ñ€Ð¸ ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð¸Ð¸", ""),
]

glo_ids = []
for term, name, desc, abbr in glossary_items:
    cat = "Ð¢ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹" if abbr else "Ð‘Ð¸Ð·Ð½ÐµÑ"
    r = create_page_in_db(GLO_DB, {
        "Ð¢ÐµÑ€Ð¼Ð¸Ð½": {"title": rich_text(term)},
        "ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ðµ": {"rich_text": rich_text(f"{name}. {desc}")},
        "ÐÐ±Ð±Ñ€ÐµÐ²Ð¸Ð°Ñ‚ÑƒÑ€Ð°": {"rich_text": rich_text(abbr)},
        "ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ": {"select": {"name": cat}}
    })
    if r:
        glo_ids.append(r["id"])
    time.sleep(0.15)

print(f"  Created {len(glo_ids)} glossary entries")

# === STEP 5: Create Risks ===
print("\n=== STEP 5: Create Risks ===")
risks = [
    ("Cherry-picking: Ð²Ñ‹Ð±Ð¾Ñ€ Ð½Ð¸Ð·ÐºÐ¾Ð¼Ð°Ñ€Ð¶Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ñ… Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¹", "ÐšÐ»Ð¸ÐµÐ½Ñ‚ Ð¼Ð¾Ð¶ÐµÑ‚ Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸ Ñ Ð½Ð¸Ð·ÐºÐ¾Ð¹ Ð¼Ð°Ñ€Ð¶Ð¾Ð¹, Ð¾ÑÑ‚Ð°Ð²Ð¸Ð² Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð¼Ð°Ñ€Ð¶Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸ Ð½ÐµÐ²Ñ‹ÐºÑƒÐ¿Ð»ÐµÐ½Ð½Ñ‹Ð¼Ð¸", "Ð¢ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹", "Ð¡Ñ€ÐµÐ´Ð½ÑÑ", "Ð’Ñ‹ÑÐ¾ÐºÐ¾Ðµ", "ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒ Ð½Ð° ÑƒÑ€Ð¾Ð²Ð½Ðµ Ð›Ð¡: Ñ€ÐµÐ½Ñ‚Ð°Ð±ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚ÑŒ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ÑÑ Ð¿Ð¾ Ð²ÑÐµÐ¹ ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸ÐºÐ°Ñ†Ð¸Ð¸, Ð° Ð½Ðµ Ð¿Ð¾ Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ð¼ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸ÑÐ¼"),
    ("Cream-skimming: ÑÐ½ÑÑ‚Ð¸Ðµ ÑÐ»Ð¸Ð²Ð¾Ðº", "ÐšÐ»Ð¸ÐµÐ½Ñ‚ ÑÐ½Ð°Ñ‡Ð°Ð»Ð° Ð·Ð°Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð¼Ð°Ñ€Ð¶Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ðµ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸, Ð·Ð°Ñ‚ÐµÐ¼ Ð¾Ñ‚ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÑ‚ÑÑ Ð¾Ñ‚ Ð½Ð¸Ð·ÐºÐ¾Ð¼Ð°Ñ€Ð¶Ð¸Ð½Ð°Ð»ÑŒÐ½Ð¾Ð³Ð¾ Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ°", "Ð¢ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹", "Ð¡Ñ€ÐµÐ´Ð½ÑÑ", "Ð’Ñ‹ÑÐ¾ÐºÐ¾Ðµ", "Ð‘Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²ÐºÐ° Ð¾Ñ‚Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¿Ñ€Ð¸ Ð¿Ñ€ÐµÐ²Ñ‹ÑˆÐµÐ½Ð¸Ð¸ 80% Ð»Ð¸Ð¼Ð¸Ñ‚Ð° ÐÐŸÐ¡Ð¡ Ð¸ Ð°Ð²Ñ‚Ð¾ÑÑÐºÐ°Ð»Ð°Ñ†Ð¸Ñ"),
    ("ÐœÐ°Ð½Ð¸Ð¿ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð½Ð¾ÑÑ‚ÑŒÑŽ Ð¾Ñ‚Ð³Ñ€ÑƒÐ·Ð¾Ðº", "ÐšÐ»Ð¸ÐµÐ½Ñ‚ Ð¸Ð»Ð¸ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€ Ð¼Ð¾Ð¶ÐµÑ‚ Ð¼Ð°Ð½Ð¸Ð¿ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ð¾Ñ€ÑÐ´ÐºÐ¾Ð¼ Ð¾Ñ‚Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð´Ð»Ñ Ð¸ÑÐºÑƒÑÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð³Ð¾ ÑƒÐ»ÑƒÑ‡ÑˆÐµÐ½Ð¸Ñ Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»ÐµÐ¹", "ÐžÑ€Ð³Ð°Ð½Ð¸Ð·Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ð¹", "ÐÐ¸Ð·ÐºÐ°Ñ", "Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ", "ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ñ€Ð°ÑÑ‡ÐµÑ‚ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¹ Ð´Ð»Ñ Ð¾Ñ‚Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¿Ð¾ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ñƒ Ñ€ÐµÐ½Ñ‚Ð°Ð±ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸"),
    ("ÐšÐ¾Ð½Ñ„Ð»Ð¸ÐºÑ‚ Ð¿Ð°Ñ€Ð°Ð»Ð»ÐµÐ»ÑŒÐ½Ñ‹Ñ… Ð¾Ð¿ÐµÑ€Ð°Ñ†Ð¸Ð¹", "ÐžÐ´Ð½Ð¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ðµ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ðµ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… Ð·Ð°ÑÐ²Ð¾Ðº Ð½Ð° Ð¾Ñ‚Ð³Ñ€ÑƒÐ·ÐºÑƒ Ð¼Ð¾Ð¶ÐµÑ‚ Ð¿Ñ€Ð¸Ð²ÐµÑÑ‚Ð¸ Ðº Ð½ÐµÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾Ð¼Ñƒ Ñ€Ð°ÑÑ‡ÐµÑ‚Ñƒ Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ¾Ð²", "Ð¢ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹", "ÐÐ¸Ð·ÐºÐ°Ñ", "Ð’Ñ‹ÑÐ¾ÐºÐ¾Ðµ", "Ð‘Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²ÐºÐ° Ð›Ð¡ Ð½Ð° Ð²Ñ€ÐµÐ¼Ñ Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¾Ñ‚Ð³Ñ€ÑƒÐ·ÐºÐ¸, Ñ‚Ñ€Ð°Ð½Ð·Ð°ÐºÑ†Ð¸Ð¾Ð½Ð½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒ"),
    ("ÐŸÑ€ÐµÐ²Ñ‹ÑˆÐµÐ½Ð¸Ðµ SLA ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð¸Ñ", "Ð—Ð°Ð´ÐµÑ€Ð¶ÐºÐ° ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð¸Ñ Ð¼Ð¾Ð¶ÐµÑ‚ Ð·Ð°Ð±Ð»Ð¾ÐºÐ¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð´Ð°Ð¶Ð¸ Ð¸ ÑƒÑ…ÑƒÐ´ÑˆÐ¸Ñ‚ÑŒ Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸Ñ Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð¼", "ÐžÑ€Ð³Ð°Ð½Ð¸Ð·Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ð¹", "Ð¡Ñ€ÐµÐ´Ð½ÑÑ", "Ð’Ñ‹ÑÐ¾ÐºÐ¾Ðµ", "Ð¢Ñ€ÐµÑ…ÑƒÑ€Ð¾Ð²Ð½ÐµÐ²Ð°Ñ Ð°Ð²Ñ‚Ð¾ÑÑÐºÐ°Ð»Ð°Ñ†Ð¸Ñ: Ð Ð‘Ð® 4Ñ‡ -> Ð”ÐŸ 8Ñ‡ -> Ð“Ð” 24Ñ‡"),
    ("ÐœÐ¾Ð»Ñ‡Ð°Ð½Ð¸Ðµ ÑÐ¾Ð³Ð»Ð°ÑÑƒÑŽÑ‰ÐµÐ³Ð¾", "Ð¡Ð¾Ð³Ð»Ð°ÑÑƒÑŽÑ‰Ð¸Ð¹ Ð½Ðµ Ñ€ÐµÐ°Ð³Ð¸Ñ€ÑƒÐµÑ‚ Ð½Ð° Ð·Ð°Ð¿Ñ€Ð¾Ñ, Ð±Ð»Ð¾ÐºÐ¸Ñ€ÑƒÑ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ", "ÐžÑ€Ð³Ð°Ð½Ð¸Ð·Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ð¹", "Ð¡Ñ€ÐµÐ´Ð½ÑÑ", "Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ", "ÐÐ²Ñ‚Ð¾ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ñ€ÐµÐ½Ñ‚Ð°Ð±ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸, ÑÑÐºÐ°Ð»Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹"),
    ("ÐÐµÐ²Ñ‹ÐºÑƒÐ¿ Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ¾Ð² Ð›Ð¡", "ÐšÐ»Ð¸ÐµÐ½Ñ‚ Ð¼Ð¾Ð¶ÐµÑ‚ Ð½Ðµ Ð²Ñ‹ÐºÑƒÐ¿Ð¸Ñ‚ÑŒ Ð¾ÑÑ‚Ð°Ð²ÑˆÐ¸ÐµÑÑ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸ Ð¿Ð¾ÑÐ»Ðµ Ñ‡Ð°ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ñ… Ð¾Ñ‚Ð³Ñ€ÑƒÐ·Ð¾Ðº", "Ð’Ð½ÐµÑˆÐ½Ð¸Ð¹", "Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ", "ÐšÑ€Ð¸Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ðµ", "Ð¡Ð°Ð½ÐºÑ†Ð¸Ð¸ Ð·Ð° Ð½ÐµÐ²Ñ‹ÐºÑƒÐ¿: ÑÐ½Ð¸Ð¶ÐµÐ½Ð¸Ðµ Ð»Ð¸Ð¼Ð¸Ñ‚Ð°, Ñ‚Ñ€ÐµÐ±Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ñ€ÐµÐ´Ð¾Ð¿Ð»Ð°Ñ‚Ñ‹, ÑÑÐºÐ°Ð»Ð°Ñ†Ð¸Ñ"),
    ("ÐšÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· (splitting)", "ÐšÐ»Ð¸ÐµÐ½Ñ‚ ÑÑ€Ð°Ð²Ð½Ð¸Ð²Ð°ÐµÑ‚ Ñ†ÐµÐ½Ñ‹ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¾Ð½Ð½Ð¾ Ñ ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð°Ð¼Ð¸ Ð¸ Ð·Ð°Ð±Ð¸Ñ€Ð°ÐµÑ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð²Ñ‹Ð³Ð¾Ð´Ð½Ñ‹Ðµ Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸", "Ð’Ð½ÐµÑˆÐ½Ð¸Ð¹", "Ð’Ñ‹ÑÐ¾ÐºÐ°Ñ", "Ð’Ñ‹ÑÐ¾ÐºÐ¾Ðµ", "Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¼ÐµÐ½ÐµÐ´Ð¶ÐµÑ€Ð° Ð¾ Ñ€Ð¸ÑÐºÐµ Ð¿Ñ€Ð¸ Ð¾Ñ‚ÐºÐ»Ð¾Ð½ÐµÐ½Ð¸Ð¸ Ð¾Ñ‚ Ñ‚Ð¸Ð¿Ð¾Ð²Ð¾Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ñ‹ Ð·Ð°ÐºÐ°Ð·Ð°"),
    ("ÐŸÐ¾Ñ‚ÐµÑ€Ñ Ð¿Ð°ÐºÐµÑ‚Ð½Ð¾Ð¹ ÑÐºÐ¸Ð´ÐºÐ¸", "ÐŸÑ€Ð¸ Ñ‡Ð°ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ñ… Ð¾Ñ‚Ð³Ñ€ÑƒÐ·ÐºÐ°Ñ… Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ Ð¿Ð¾Ñ‚ÐµÑ€ÑÐ½Ð° ÑÐºÐ¸Ð´ÐºÐ°, Ñ€Ð°ÑÑÑ‡Ð¸Ñ‚Ð°Ð½Ð½Ð°Ñ Ð½Ð° Ð²ÐµÑÑŒ Ð¾Ð±ÑŠÐµÐ¼", "Ð¢ÐµÑ…Ð½Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹", "Ð¡Ñ€ÐµÐ´Ð½ÑÑ", "Ð’Ñ‹ÑÐ¾ÐºÐ¾Ðµ", "ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»ÑŒ Ð¾ÑÑ‚Ð°Ñ‚ÐºÐ° Ð¿ÐµÑ€ÐµÐ´ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÐµÐ½Ð¸ÐµÐ¼ ÑÐºÐ¸Ð´ÐºÐ¸, Ð¿ÐµÑ€ÐµÑÑ‡ÐµÑ‚ Ð¿Ñ€Ð¸ Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¸ Ð¾Ð±ÑŠÐµÐ¼Ð°"),
    ("ÐžÑ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ðµ Ð·Ð°Ð¼ÐµÑÑ‚Ð¸Ñ‚ÐµÐ»Ñ ÑÐ¾Ð³Ð»Ð°ÑÑƒÑŽÑ‰ÐµÐ³Ð¾", "ÐŸÑ€Ð¸ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ð¸ ÑÐ¾Ð³Ð»Ð°ÑÑƒÑŽÑ‰ÐµÐ³Ð¾ Ð¿Ñ€Ð¾Ñ†ÐµÑÑ Ð¼Ð¾Ð¶ÐµÑ‚ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒÑÑ", "ÐžÑ€Ð³Ð°Ð½Ð¸Ð·Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ð¹", "ÐÐ¸Ð·ÐºÐ°Ñ", "Ð¡Ñ€ÐµÐ´Ð½ÐµÐµ", "ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ°Ñ ÑÑÐºÐ°Ð»Ð°Ñ†Ð¸Ñ Ð½Ð° ÑÐ»ÐµÐ´ÑƒÑŽÑ‰Ð¸Ð¹ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ Ð¿Ñ€Ð¸ Ð¾Ñ‚ÑÑƒÑ‚ÑÑ‚Ð²Ð¸Ð¸ Ð·Ð°Ð¼ÐµÑÑ‚Ð¸Ñ‚ÐµÐ»Ñ"),
]

risk_ids = []
for name, desc, cat, prob, impact, mitigation in risks:
    r = create_page_in_db(RISK_DB, {
        "ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ": {"title": rich_text(name)},
        "ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ": {"rich_text": rich_text(desc)},
        "ÐšÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ñ": {"select": {"name": cat}},
        "Ð’ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚ÑŒ": {"select": {"name": prob}},
        "Ð’Ð»Ð¸ÑÐ½Ð¸Ðµ": {"select": {"name": impact}},
        "Ð¡Ñ‚Ð°Ñ‚ÑƒÑ": {"select": {"name": "ÐžÑ‚ÐºÑ€Ñ‹Ñ‚"}},
        "ÐœÐ¸Ñ‚Ð¸Ð³Ð°Ñ†Ð¸Ñ": {"rich_text": rich_text(mitigation)}
    })
    if r:
        risk_ids.append(r["id"])
    time.sleep(0.15)

print(f"  Created {len(risk_ids)} risks")

# === STEP 6: Create Version History ===
print("\n=== STEP 6: Create Version History ===")
versions = [
    ("v1.0.0", "2025-12-15", "ÐŸÐµÑ€Ð²Ð°Ñ Ð²ÐµÑ€ÑÐ¸Ñ Ð¤Ðœ. Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ð¹ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¾Ð½Ð°Ð» ÐºÐ¾Ð½Ñ‚Ñ€Ð¾Ð»Ñ Ñ€ÐµÐ½Ñ‚Ð°Ð±ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸.", "Major"),
    ("v1.1.0", "2026-01-15", "Ð”Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ñ‹ Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð° Ñ‡Ð°ÑÑ‚Ð¸Ñ‡Ð½Ñ‹Ñ… Ð¾Ñ‚Ð³Ñ€ÑƒÐ·Ð¾Ðº, SLA ÑÐ¾Ð³Ð»Ð°ÑÐ¾Ð²Ð°Ð½Ð¸Ñ, ÑÑÐºÐ°Ð»Ð°Ñ†Ð¸Ð¸.", "Minor"),
    ("v1.2.0", "2026-01-25", "Ð”Ð¾Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð½Ñ‹ Ð±Ð¸Ð·Ð½ÐµÑ-Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð°, Ð´Ð¾Ð±Ð°Ð²Ð»ÐµÐ½Ñ‹ ÑÐ°Ð½ÐºÑ†Ð¸Ð¸ Ð·Ð° Ð½ÐµÐ²Ñ‹ÐºÑƒÐ¿.", "Minor"),
    ("v1.2.1", "2026-01-29", "Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ñ 31 Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ Ð¿Ð¾ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ð¼ Ð°ÑƒÐ´Ð¸Ñ‚Ð°: Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð¾Ð»Ð¾Ð³Ð¸Ñ, Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ, ÑƒÑ‚Ð¾Ñ‡Ð½ÐµÐ½Ð¸Ñ Ð±Ð¸Ð·Ð½ÐµÑ-Ð¿Ñ€Ð°Ð²Ð¸Ð».", "Patch"),
]

ver_ids = []
for ver, date, changes, vtype in versions:
    r = create_page_in_db(VER_DB, {
        "Ð’ÐµÑ€ÑÐ¸Ñ": {"title": rich_text(ver)},
        "Ð”Ð°Ñ‚Ð°": {"date": {"start": date}},
        "Ð˜Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ñ": {"rich_text": rich_text(changes)},
        "Ð¢Ð¸Ð¿": {"select": {"name": vtype}}
    })
    if r:
        ver_ids.append(r["id"])
    time.sleep(0.15)

print(f"  Created {len(ver_ids)} version entries")

# === STEP 7: Link relations ===
print("\n=== STEP 7: Link relations ===")

# Link glossary to FM
for gid in glo_ids:
    api("PATCH", f"pages/{gid}", {"properties": {"Ð¤Ðœ": {"relation": [{"id": fm_page_id}]}}})
    time.sleep(0.08)
print(f"  Linked {len(glo_ids)} glossary -> FM")

# Link requirements to FM
for rid in req_ids:
    api("PATCH", f"pages/{rid}", {"properties": {"Ð¤Ðœ": {"relation": [{"id": fm_page_id}]}}})
    time.sleep(0.08)
print(f"  Linked {len(req_ids)} requirements -> FM")

# Link risks to FM
for rkid in risk_ids:
    api("PATCH", f"pages/{rkid}", {"properties": {"Ð¤Ðœ": {"relation": [{"id": fm_page_id}]}}})
    time.sleep(0.08)
print(f"  Linked {len(risk_ids)} risks -> FM")

# Link versions to FM
for vid in ver_ids:
    api("PATCH", f"pages/{vid}", {"properties": {"Ð¤Ðœ": {"relation": [{"id": fm_page_id}]}}})
    time.sleep(0.08)
print(f"  Linked {len(ver_ids)} versions -> FM")

# === SUMMARY ===
print("\n" + "=" * 60)
print("PUBLISH COMPLETE")
print("=" * 60)
print(f"  FM Page:      {fm_page_url}")
print(f"  Requirements: {len(req_ids)}")
print(f"  Glossary:     {len(glo_ids)}")
print(f"  Risks:        {len(risk_ids)}")
print(f"  Versions:     {len(ver_ids)}")
print("=" * 60)
